{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a62193",
   "metadata": {},
   "source": [
    "# Python bootcamp\n",
    "\n",
    "This bootcamp will be teaching python through a just-in-time programming approach. That is, instead of walking you through fundamentals step by step, we will jump right into analyzing code and teaching you the tools necessary to understand and modify that code as we go. You can find a more systematic review of python fundamentals in the subfolders of this repository, with the following organization:\n",
    "- ``0_getting_started`` contains information on what python is and its current popularity and use.\n",
    "- ``1_fundamentals`` gives an intro to datatypes, the building blocks of any programming language.\n",
    "- ``2_functions`` introduces you to functions and scope in python.\n",
    "- ``3_classes`` gives a basic introduction to python classes and a more advanced example of an OLS class.\n",
    "- ``5_list_comprehensions`` introduces list comprehensions, an efficient method of creating iterable objects.\n",
    "\n",
    "This notebook starts with an abitious goal: the creation if a python ``class`` object (don't worry, we'll tell you what this is) that runs OLS. To do this, we will introduce concepts like importing packages, defining functions, and manipulating numpy matrices, then organize all of these into a class object.  Specifically our goals are going to be:\n",
    "- Make a linear projection function with b0, b1, x as input, y as output\n",
    "- Write a data generating function\n",
    "- Give a brief explanation of the scipy.optimize.minimize function\n",
    "- Minimize the squared errors to estimate b0 and b1\n",
    "- Create a class that implements the same minimization, \n",
    "  that takes data in instantiation, and has an 'estimate' method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e4c62",
   "metadata": {},
   "source": [
    "## Package imports\n",
    "\n",
    "We will be using object types and methods from a couple of different packages in python. These packages must first be installed in the environment you are working in. For the datahub environment we are using for this bootcamp, the necessary packages are already installed. If you want to work on your own computer, you will need to install these using either ``pip``, python's native installer, or preferably the package manager Anaconda. Lucy will go over installation using Anaconda on Friday. For now, note that python packages are importing using the ``import`` command, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13acb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for later\n",
    "import numpy as np\n",
    "from scipy.stats import distributions as iid\n",
    "from scipy.stats import rv_continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eba71a",
   "metadata": {},
   "source": [
    "## Functions: Building blocks of an OLS class\n",
    "We are going to start by writing functions for the main actions of an OLS class and for generating the simmulated data we will use to test our OLS functions. An OLS estimator must do two things; define a linear model and (to start) minimize the sum of squared errors. We can summarize these activities as:\n",
    "\n",
    "1. Linear projection: Predict \"y\" given a set of betas and data X\n",
    "    - inputs: b0, b1, x\n",
    "    - outputs: y hat\n",
    "2. Define the data\n",
    "    - Inputs: N, true betas\n",
    "    - Outputs: y, X matrices\n",
    "3. Minimizer function: minimizes the squared distance between the linear projection and y\n",
    "    - inputs: A function to minimize (SSE)\n",
    "    - output: betas that minimize that function\n",
    "    \n",
    "### 1. Linear projection\n",
    "Suppose we have a vector X that is N by 2, where the first column is a column of ones, and a vector of betas: b = [b0, b1]. The projection matrix, or the matrix that predicts y, is given by $Xb$. \n",
    "\n",
    "Note that the text in red documents the function, telling future users (and your future self! What the function takes in, and what it returns. This is optional, but good practice. Tip: being detailed about what data types are acceptable will help you even more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698efc88",
   "metadata": {},
   "source": [
    "### Quick aside: Matrix algebra and some helpful numpy functions.\n",
    "``numpy`` is a python package that contains number generators, its own matrix objects and methods, and more! Plus it's blazing fast. The building blocks of numpy are called numpy arrays, and they can have as many dimentions as you want. The next block of code shows you how to create some numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdee978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My matrix shapes are\n",
      " m1: (3,)\n",
      " m2: (1, 3)\n",
      " m3: (2, 3)\n",
      " m4: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "m1 = np.array([1, 2, 3]) # shape (3,)\n",
    "m2 = np.array([[1, 2, 3]]) # shape (1,3)\n",
    "m3 = np.array([[1, 2, 3], # shape (2,3)\n",
    "               [4, 5, 6]])\n",
    "m4 = np.array([[2], [2], [2]]) # shape (3,1)\n",
    "# We can inspect an array's shape\n",
    "print(\"My matrix shapes are\\n m1: %s\\n m2: %s\\n m3: %s\\n m4: %s\" % (m1.shape, m2.shape, m3.shape, m4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe1def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplying m3, 4 gives:\n",
      " [[12]\n",
      " [30]]\n",
      "Element-wise multiplying m1, m3 gives:\n",
      " [[1 4 9]]\n"
     ]
    }
   ],
   "source": [
    "# numpy arrays can be added with +, matrix multiplied with @, or element-wise multiplied with *:\n",
    "matmult = m3@m4\n",
    "elementmult = m2*m1\n",
    "print(\"Matrix multiplying m3, 4 gives:\\n %s\" % matmult)\n",
    "print(\"Element-wise multiplying m1, m3 gives:\\n %s\" % elementmult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1828c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n",
      "[ 4  8 12]\n"
     ]
    }
   ],
   "source": [
    "# they can also be (element-wise) raised to powers, etc:\n",
    "print(m1**2)\n",
    "print(m1*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a9ce4",
   "metadata": {},
   "source": [
    "### Back to the linear projection function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b62dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_projection(X, b):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - X: numpy array of dimensions NxK. The first column is assumed to be a column of ones.\n",
    "        - b: numpy array of dimensions Kx1.\n",
    "    Returns:\n",
    "        - Xb, an Nx1 numpy array\n",
    "    '''\n",
    "    # make sure b is the right shape\n",
    "    b = b.reshape((len(b),1))\n",
    "    return X@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62502c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91823303],\n",
       "       [1.00742063],\n",
       "       [1.1260404 ],\n",
       "       [1.12395384],\n",
       "       [1.2477445 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "X = np.c_[np.ones((5,1)), np.random.rand(5,1)]\n",
    "b = np.random.rand(2,1)\n",
    "linear_projection(X,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c1539",
   "metadata": {},
   "source": [
    "### 2. Data generating process\n",
    "We will create data that has N observations and a \"true\" but noisy relationship between $x$ and $y$. This type of data is used in Monte Carlo simulations to test theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d574a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(beta, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - beta: A Kx1 numpy array. True beta from which to generate data.\n",
    "        - N: Number of observations the data should have\n",
    "    Returns:\n",
    "        - X: A numpy array of random data with shape NxK\n",
    "        - y: A numpy array generated by Xbeta + e with shape Nx1\n",
    "    '''\n",
    "    # create an X vector\n",
    "    # note I instantiate iid.norm() and call method rvs() in the same step!\n",
    "    x = iid.norm().rvs((N,1))\n",
    "\n",
    "    # create a random error\n",
    "    e = iid.norm().rvs((N,1))\n",
    "    # add an intercept by horizontally stacking x with an array of ones,\n",
    "    X = np.c_[np.ones((N,1)), x]\n",
    "    # make sure beta is the right shape: Kx1\n",
    "    beta = beta.reshape((beta.shape[0],1))\n",
    "    # create y\n",
    "    y = linear_projection(X, beta) + e\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef2c7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  0.42549221],\n",
       "        [ 1.        ,  0.36560729],\n",
       "        [ 1.        , -0.92767122],\n",
       "        [ 1.        , -0.56178431],\n",
       "        [ 1.        ,  0.93022811]]),\n",
       " array([[ 2.14178002],\n",
       "        [ 2.41450946],\n",
       "        [-0.57991515],\n",
       "        [-0.5496822 ],\n",
       "        [ 3.76518356]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "beta_true = np.array([1,1])\n",
    "dataGenerator(beta_true, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586ef35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is 100 x 2\n",
      "y is 100 x 1\n"
     ]
    }
   ],
   "source": [
    "# create data\n",
    "beta_true = np.array([2,8])\n",
    "N = 100\n",
    "\n",
    "X, y = dataGenerator(beta_true, N)\n",
    "\n",
    "# test shapes!\n",
    "print(\"X is %s x %s\" % (X.shape[0], X.shape[1]))\n",
    "print(\"y is %s x %s\" % (y.shape[0], y.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5290c5",
   "metadata": {},
   "source": [
    "### 3. Minimizer function\n",
    "In order to minimize, we are going to use a minimizer function from ``scipy.optimize``. The documentation for this function can be found [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html), but the key arguments are the following:\n",
    "* ``fun``: the function to be minimized. This must be a function of only one input; if there are multiple inputs, we will \"mask\" these using lambda functions. Note that functions can be passed to other functions! Functions are objects just like other python data types, so we can pass them around using their name.\n",
    "* ``x0``: The start guess for the solution. In the case that the solution has a global minimum (as the least squares problem does) the choice will only affect computation time.\n",
    "\n",
    "Thus the final syntax is `minimize(fun = function(x), x0 = [start guess])`.\n",
    "\n",
    "The function returns an instance of the ``OptimizeResult`` class, which has several attributes. The only one we will be interested in for now is ``x``, the solution that solves the minimization.\n",
    "\n",
    "Let's set up a function that returns the object we want to minimize for OLS: the sum of squared errors. Note that the SSE is given by:\n",
    "\n",
    "$$SSE = \\sum_i (\\widehat{y}_i - y_i)^2$$\n",
    "\n",
    "Implementing this in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734b3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(y, X, b):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - y: Numpy array Nx1\n",
    "        - X: Numpy array NxK\n",
    "        - b: Numpy array Kx1\n",
    "    '''\n",
    "    yhat = linear_projection(X, b)\n",
    "    sse = np.sum((yhat - y)**2)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162d133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.15309346674218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse(y,X,beta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e2782",
   "metadata": {},
   "source": [
    "Now we can minimize this function, making it a function of just one variable by masking the other inputs in a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0b5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1fb1be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 110.93531136213308\n",
       " hess_inv: array([[ 0.00504965, -0.00044726],\n",
       "       [-0.00044726,  0.00402937]])\n",
       "      jac: array([ 9.53674316e-07, -9.53674316e-07])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 27\n",
       "      nit: 6\n",
       "     njev: 9\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([2.00911686, 8.04008407])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember the syntax: \n",
    "# minimize(fun = function(x), x0 = [start guess])\n",
    "# the lambda function allows sse to be a function of only x, the other inputs\n",
    "# come from the variables X and y we already defined.\n",
    "minimize(lambda x: sse(y, X, x), x0 = [0,0])\n",
    "# as expected, we get an intercept of around 2 and a slope around 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee0f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 10059.21721418913\n",
       " hess_inv: array([[5.12932394e-05, 5.13365240e-05],\n",
       "       [5.13365240e-05, 5.47497049e-05]])\n",
       "      jac: array([0.00012207, 0.        ])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 42\n",
       "      nit: 7\n",
       "     njev: 14\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([1.99789901, 8.00919576])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do it again with a higher N, letting the LLN work for us!\n",
    "X, y = dataGenerator(beta_true, 10000)\n",
    "minimize(lambda x: sse(y, X, x), x0 = [0,0])\n",
    "# now it's even more accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16164ed8",
   "metadata": {},
   "source": [
    "## Creating an OLS class\n",
    "Now let's take our functions and organize them into an OLS class. What is a python class? \n",
    "\n",
    "python classes are objects that have attributes and methods. These objects are abstract in the sense that a class in the abstract is used to \"instantiate\" specific \"instances\" of the class. For example, here we will create a class called OLS, and will create several instantiations of specific OLS models. That is, the OLS class might have attributes like X and y data, but an OLS class _instance_ will have _specific_ data for X and y.\n",
    "\n",
    "To define a class, we use ``class ClassName:``, followed by indented lines (convention is to name classes with upper case).\n",
    "\n",
    "Classes have 3 components:\n",
    "* **The constructor** this is a method (think: function) that creates an _instance_ of the class. This component must be present in all classes, as it is the engine that creates the object. It looks like ``def __init__(self):``\n",
    "* **Attributes** These are attributes that all instances of a class have. They can be anything, or not exist at all. For example, consider a Student class that stores information for a student database. In that case, we might want students to have attributes like a student ID, gender, age, etc. These can vary by instance of the Student class, but all instances of ``Student`` have one. If we imagine an alternative class called `Alien()`, attributes might include home planet and and number of limbs.\n",
    "* **Methods** Methods are functions that belong to a class. They may return output or not. For example, we may want to write a method that calculates a student's GPA given a series of numeric grades. In the case of OLS, out main method will be to estimate beta.\n",
    "\n",
    "The simplest class is made up of only a constructor, and the simplest constructor doesn't do anything except create an instance of the class. This looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b67c8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS:\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecee924",
   "metadata": {},
   "source": [
    "Now to create an _instance_ of the class, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88466c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OLS at 0x108b7e220>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myOLSmodel = OLS()\n",
    "myOLSmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c716fa5",
   "metadata": {},
   "source": [
    "However, this OLS model is not very interesting. For example, we might think that each OLS model might have data associated with it. Therefore, we can require that the instantiation receive X and y data, and create attributes from these data. Attributes \"belong\" to the class, and can be accessed with the syntax ``classInstance.attribute``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d33b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS:\n",
    "    # constructor\n",
    "    def __init__(self, X, y):\n",
    "        # define attributes\n",
    "        self.X = X\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fce7d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.ones((5,1))\n",
    "x_test = np.ones((5,2))*3\n",
    "\n",
    "myOLS = OLS(x_test, y_test)\n",
    "myOLS.y # note that within OLS(), the argument is called y!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac3d98",
   "metadata": {},
   "source": [
    "Now that our OLS class has attributes, we want it to calculate something! So we are going to give it **methods**, which are functions that belong to a class. For example, let's add our linear_projection function to this class as a method. In order to do this, we define the function within the class body, and we add another special argument to the method ``self``. By adding self as an argument, we will have access to all the attributes and methods that the class contains! For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4375cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS:\n",
    "    # constructor\n",
    "    def __init__(self, X, y):\n",
    "        # define attributes\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    # ------- methods --------\n",
    "    # linear projection\n",
    "    def linear_projection(self, b):\n",
    "        b = b.reshape((len(b),1))\n",
    "        return self.X@b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094ac01",
   "metadata": {},
   "source": [
    "What do you notice is different about linear_projection the method?\n",
    "1. It has ``self`` as an argument. This allows it to know about attributes and even other methods contained in the class.\n",
    "2. I took away X as an argument, instead calling ``self.X`` in the method body. How can this be?? Since X is now an _attribute_ of the class, and the method has the ``self`` argument, ``self.X`` is saying \"grab the X that you defined as the class attribute\". This way we don't have to constantly be entering our data into all the function calls, because our OLS instance is storing it for us! Here's how we would use this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420cc3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.500279  ],\n",
       "       [0.87359401],\n",
       "       [2.03864013],\n",
       "       ...,\n",
       "       [3.76198732],\n",
       "       [2.47630347],\n",
       "       [3.62583155]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myOLS = OLS(X, y)\n",
    "\n",
    "# method call with instanceName.method. Only input is b; we don't have to pass \"self\" to the method.\n",
    "myOLS.linear_projection(np.array([2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83144b",
   "metadata": {},
   "source": [
    "Now let's add our other methods. What other changes do you notice to these expressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6f09f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OLS:\n",
    "    # constructor\n",
    "    def __init__(self, X, y):\n",
    "        # define attributes\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    # ------- methods --------\n",
    "    # linear projection\n",
    "    def linear_projection(self, b):\n",
    "        b = b.reshape((len(b),1))\n",
    "        return self.X@b\n",
    "    \n",
    "    # SSE\n",
    "    def sse(self, b): # used to be a f'm of y, X, and b. Now only need b!\n",
    "        yhat = self.linear_projection(b)\n",
    "        sse = np.sum((yhat - self.y)**2)\n",
    "        return sse\n",
    "    \n",
    "    # minimize the SSE\n",
    "    def estimate(self, x0 = [0,0]):\n",
    "        # default initial guess of [0,0]\n",
    "        sol = minimize(self.sse, x0 = x0)\n",
    "        return sol.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a8811",
   "metadata": {},
   "source": [
    "What happened to the arguments in minimize?? Here something cool happens, and it actually starts with the `sse` function. Now that `X` and `y` are attributes of the class, the `self.sse()` method knows what they are thanks to the `self` argument that is implicitly passed into it! Therefore we can call `sse()` as only a function of one argument: `b`. Here's proof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1c9426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483818.64196098014"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model1 = OLS(X, y)\n",
    "\n",
    "# call sse method\n",
    "model1.sse(np.array([2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a09912",
   "metadata": {},
   "source": [
    "Now that `OLS.sse()` is only a function of one argument, we can omit the arguments altogether in the minimze function, and call it just by its name, `self.sse`. This is an example of passing a function to another function; when there is only 1 argument, we only need its name. And because of the class structure, it already knows that the single argument is what it is minimizing over! Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b542b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99789901, 8.00919576])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the solve_OLS() method\n",
    "model1.estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e763bf0",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Try these out for yourself:\n",
    "1. After estimating $\\widehat{\\beta}$, add it as an attribute of the OLS class.\n",
    "2. Estimate the White-robust SEs. There are a few ways to do this; which do you prefer? Why?\n",
    "     - Estimate and return them with beta in a tuple\n",
    "     - Estimate them with beta and add as an attribute\n",
    "     - Write a method that calculates and returns them upon request (nice code will avoid re-estimating the betas each time you do this. How can this be avoided?)\n",
    "3. Rewrite the estimation in terms of matrix algebra instead of a minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b0f765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS:\n",
    "    # constructor\n",
    "    def __init__(self, X, y):\n",
    "        # define attributes\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    # ------- methods --------\n",
    "    # linear projection\n",
    "    def linear_projection(self, b):\n",
    "        b = b.reshape((len(b),1))\n",
    "        return self.X@b\n",
    "    # SSE\n",
    "    def sse(self, b): # used to be a f'm of y, X, and b. Now only need b!\n",
    "        yhat = self.linear_projection(b)\n",
    "        sse = np.sum((yhat - self.y)**2)\n",
    "        return sse\n",
    "    # minimize the SSE\n",
    "    def estimate(self, x0 = [0,0]):\n",
    "        # default initial guess of [0,0]\n",
    "        sol = minimize(self.sse, x0 = x0)\n",
    "        # Exercise 1\n",
    "        ...\n",
    "        \n",
    "        return sol.x\n",
    "        \n",
    "        \n",
    "    # Exercise 2\n",
    "    def whiteSEs(self):\n",
    "        if not hasattr(self, 'beta'):\n",
    "            self.estimate()\n",
    "        ...\n",
    "    \n",
    "     # Exercise 3\n",
    "    def estimate_matAlg(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10519bd5",
   "metadata": {},
   "source": [
    "### Test our work\n",
    "I test the results against the ``statsmodels`` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c299e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60797fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99789901, 8.00919576])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate\n",
    "model = OLS(X, y)\n",
    "# run\n",
    "model.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f62d7fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White SEs: \n",
      "[[0.01003197 0.00160577]\n",
      " [0.00160577 0.01030198]]\n",
      "beta_hat (minimizer): \n",
      " [1.99789901 8.00919576]\n",
      "beta_hat (matrix algebra): \n",
      "[[1.99789902]\n",
      " [8.00919577]]\n"
     ]
    }
   ],
   "source": [
    "print(\"White SEs: \\n%s\" % model.whiteSEs()**(1/2))\n",
    "print(\"beta_hat (minimizer): \\n %s\" % model.beta)\n",
    "print(\"beta_hat (matrix algebra): \\n%s\" % model.estimate_matAlg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15c24d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_ols = sm.OLS(y, X).fit(cov_type='HC0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fa84f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels White SEs:\n",
      " [[0.01003197 0.00160577]\n",
      " [0.00160577 0.01030198]]\n",
      "statsmodels beta_hat:\n",
      "[1.99789902 8.00919577]\n"
     ]
    }
   ],
   "source": [
    "print(\"statsmodels White SEs:\\n %s\" % robust_ols.cov_params()**(1/2))\n",
    "print(\"statsmodels beta_hat:\\n%s\" % robust_ols.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
